{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6671e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GitRefs(branches=[GitRefInfo(name='main', ref='refs/heads/main', target_commit='799ebd76788d9da7a2d720cb4f5eda481eb336fe')], converts=[], tags=[], pull_requests=None)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import list_repo_refs\n",
    "list_repo_refs(\"mlsquare/exp-lora-ada-2\", repo_type=\"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ef78b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GitCommitInfo(commit_id='799ebd76788d9da7a2d720cb4f5eda481eb336fe', authors=['saddlepoint'], created_at=datetime.datetime(2024, 2, 1, 2, 13, 12, tzinfo=datetime.timezone.utc), title='Upload model', message='', formatted_title=None, formatted_message=None), GitCommitInfo(commit_id='ed7b2a7cf57c0a7c25269f96048e62a6e55f8cdb', authors=['saddlepoint'], created_at=datetime.datetime(2024, 2, 1, 2, 13, 7, tzinfo=datetime.timezone.utc), title='initial commit', message='', formatted_title=None, formatted_message=None)]\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import list_repo_commits\n",
    "cm = list_repo_commits(\"mlsquare/exp-lora-ada-2\", repo_type=\"model\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16197b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/soma/opt/anaconda3/envs/shane/lib/python3.9/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from modeling_mamba import MambaForCausalLM\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "model = MambaForCausalLM.from_pretrained('Q-bert/Mamba-130M')\n",
    "tokenizer = AutoTokenizer.from_pretrained('Q-bert/Mamba-130M')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95afe54f",
   "metadata": {},
   "source": [
    "# model merging tutorial\n",
    "https://lightning.ai/lightning-ai/studios/efficient-linear-model-merging-for-llms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3207704e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MambaConfig {\n",
       "  \"_name_or_path\": \"Q-bert/Mamba-130M\",\n",
       "  \"architectures\": [\n",
       "    \"MambaForCausalLM\"\n",
       "  ],\n",
       "  \"auto_map\": {\n",
       "    \"AutoConfig\": \"Q-bert/Mamba-130M--configuration_mamba.MambaConfig\",\n",
       "    \"AutoModelForCausalLM\": \"Q-bert/Mamba-130M--modeling_mamba.MambaForCausalLM\"\n",
       "  },\n",
       "  \"bias\": false,\n",
       "  \"conv_bias\": true,\n",
       "  \"d_conv\": 4,\n",
       "  \"d_inner\": 1536,\n",
       "  \"d_model\": 768,\n",
       "  \"d_state\": 16,\n",
       "  \"dt_rank\": 48,\n",
       "  \"expand\": 2,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"model_type\": \"mamba\",\n",
       "  \"n_layer\": 24,\n",
       "  \"pad_vocab_size_multiple\": 8,\n",
       "  \"torch_dtype\": \"float32\",\n",
       "  \"transformers_version\": \"4.37.1\",\n",
       "  \"vocab_size\": 50280\n",
       "}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d9dbb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['model.embedding.weight', 'model.layers.0.A_log', 'model.layers.0.D', 'model.layers.0.in_proj.weight', 'model.layers.0.conv1d.weight', 'model.layers.0.conv1d.bias', 'model.layers.0.x_proj.weight', 'model.layers.0.dt_proj.weight', 'model.layers.0.dt_proj.bias', 'model.layers.0.out_proj.weight', 'model.layers.0.norm.weight', 'model.layers.1.A_log', 'model.layers.1.D', 'model.layers.1.in_proj.weight', 'model.layers.1.conv1d.weight', 'model.layers.1.conv1d.bias', 'model.layers.1.x_proj.weight', 'model.layers.1.dt_proj.weight', 'model.layers.1.dt_proj.bias', 'model.layers.1.out_proj.weight', 'model.layers.1.norm.weight', 'model.layers.2.A_log', 'model.layers.2.D', 'model.layers.2.in_proj.weight', 'model.layers.2.conv1d.weight', 'model.layers.2.conv1d.bias', 'model.layers.2.x_proj.weight', 'model.layers.2.dt_proj.weight', 'model.layers.2.dt_proj.bias', 'model.layers.2.out_proj.weight', 'model.layers.2.norm.weight', 'model.layers.3.A_log', 'model.layers.3.D', 'model.layers.3.in_proj.weight', 'model.layers.3.conv1d.weight', 'model.layers.3.conv1d.bias', 'model.layers.3.x_proj.weight', 'model.layers.3.dt_proj.weight', 'model.layers.3.dt_proj.bias', 'model.layers.3.out_proj.weight', 'model.layers.3.norm.weight', 'model.layers.4.A_log', 'model.layers.4.D', 'model.layers.4.in_proj.weight', 'model.layers.4.conv1d.weight', 'model.layers.4.conv1d.bias', 'model.layers.4.x_proj.weight', 'model.layers.4.dt_proj.weight', 'model.layers.4.dt_proj.bias', 'model.layers.4.out_proj.weight', 'model.layers.4.norm.weight', 'model.layers.5.A_log', 'model.layers.5.D', 'model.layers.5.in_proj.weight', 'model.layers.5.conv1d.weight', 'model.layers.5.conv1d.bias', 'model.layers.5.x_proj.weight', 'model.layers.5.dt_proj.weight', 'model.layers.5.dt_proj.bias', 'model.layers.5.out_proj.weight', 'model.layers.5.norm.weight', 'model.layers.6.A_log', 'model.layers.6.D', 'model.layers.6.in_proj.weight', 'model.layers.6.conv1d.weight', 'model.layers.6.conv1d.bias', 'model.layers.6.x_proj.weight', 'model.layers.6.dt_proj.weight', 'model.layers.6.dt_proj.bias', 'model.layers.6.out_proj.weight', 'model.layers.6.norm.weight', 'model.layers.7.A_log', 'model.layers.7.D', 'model.layers.7.in_proj.weight', 'model.layers.7.conv1d.weight', 'model.layers.7.conv1d.bias', 'model.layers.7.x_proj.weight', 'model.layers.7.dt_proj.weight', 'model.layers.7.dt_proj.bias', 'model.layers.7.out_proj.weight', 'model.layers.7.norm.weight', 'model.layers.8.A_log', 'model.layers.8.D', 'model.layers.8.in_proj.weight', 'model.layers.8.conv1d.weight', 'model.layers.8.conv1d.bias', 'model.layers.8.x_proj.weight', 'model.layers.8.dt_proj.weight', 'model.layers.8.dt_proj.bias', 'model.layers.8.out_proj.weight', 'model.layers.8.norm.weight', 'model.layers.9.A_log', 'model.layers.9.D', 'model.layers.9.in_proj.weight', 'model.layers.9.conv1d.weight', 'model.layers.9.conv1d.bias', 'model.layers.9.x_proj.weight', 'model.layers.9.dt_proj.weight', 'model.layers.9.dt_proj.bias', 'model.layers.9.out_proj.weight', 'model.layers.9.norm.weight', 'model.layers.10.A_log', 'model.layers.10.D', 'model.layers.10.in_proj.weight', 'model.layers.10.conv1d.weight', 'model.layers.10.conv1d.bias', 'model.layers.10.x_proj.weight', 'model.layers.10.dt_proj.weight', 'model.layers.10.dt_proj.bias', 'model.layers.10.out_proj.weight', 'model.layers.10.norm.weight', 'model.layers.11.A_log', 'model.layers.11.D', 'model.layers.11.in_proj.weight', 'model.layers.11.conv1d.weight', 'model.layers.11.conv1d.bias', 'model.layers.11.x_proj.weight', 'model.layers.11.dt_proj.weight', 'model.layers.11.dt_proj.bias', 'model.layers.11.out_proj.weight', 'model.layers.11.norm.weight', 'model.layers.12.A_log', 'model.layers.12.D', 'model.layers.12.in_proj.weight', 'model.layers.12.conv1d.weight', 'model.layers.12.conv1d.bias', 'model.layers.12.x_proj.weight', 'model.layers.12.dt_proj.weight', 'model.layers.12.dt_proj.bias', 'model.layers.12.out_proj.weight', 'model.layers.12.norm.weight', 'model.layers.13.A_log', 'model.layers.13.D', 'model.layers.13.in_proj.weight', 'model.layers.13.conv1d.weight', 'model.layers.13.conv1d.bias', 'model.layers.13.x_proj.weight', 'model.layers.13.dt_proj.weight', 'model.layers.13.dt_proj.bias', 'model.layers.13.out_proj.weight', 'model.layers.13.norm.weight', 'model.layers.14.A_log', 'model.layers.14.D', 'model.layers.14.in_proj.weight', 'model.layers.14.conv1d.weight', 'model.layers.14.conv1d.bias', 'model.layers.14.x_proj.weight', 'model.layers.14.dt_proj.weight', 'model.layers.14.dt_proj.bias', 'model.layers.14.out_proj.weight', 'model.layers.14.norm.weight', 'model.layers.15.A_log', 'model.layers.15.D', 'model.layers.15.in_proj.weight', 'model.layers.15.conv1d.weight', 'model.layers.15.conv1d.bias', 'model.layers.15.x_proj.weight', 'model.layers.15.dt_proj.weight', 'model.layers.15.dt_proj.bias', 'model.layers.15.out_proj.weight', 'model.layers.15.norm.weight', 'model.layers.16.A_log', 'model.layers.16.D', 'model.layers.16.in_proj.weight', 'model.layers.16.conv1d.weight', 'model.layers.16.conv1d.bias', 'model.layers.16.x_proj.weight', 'model.layers.16.dt_proj.weight', 'model.layers.16.dt_proj.bias', 'model.layers.16.out_proj.weight', 'model.layers.16.norm.weight', 'model.layers.17.A_log', 'model.layers.17.D', 'model.layers.17.in_proj.weight', 'model.layers.17.conv1d.weight', 'model.layers.17.conv1d.bias', 'model.layers.17.x_proj.weight', 'model.layers.17.dt_proj.weight', 'model.layers.17.dt_proj.bias', 'model.layers.17.out_proj.weight', 'model.layers.17.norm.weight', 'model.layers.18.A_log', 'model.layers.18.D', 'model.layers.18.in_proj.weight', 'model.layers.18.conv1d.weight', 'model.layers.18.conv1d.bias', 'model.layers.18.x_proj.weight', 'model.layers.18.dt_proj.weight', 'model.layers.18.dt_proj.bias', 'model.layers.18.out_proj.weight', 'model.layers.18.norm.weight', 'model.layers.19.A_log', 'model.layers.19.D', 'model.layers.19.in_proj.weight', 'model.layers.19.conv1d.weight', 'model.layers.19.conv1d.bias', 'model.layers.19.x_proj.weight', 'model.layers.19.dt_proj.weight', 'model.layers.19.dt_proj.bias', 'model.layers.19.out_proj.weight', 'model.layers.19.norm.weight', 'model.layers.20.A_log', 'model.layers.20.D', 'model.layers.20.in_proj.weight', 'model.layers.20.conv1d.weight', 'model.layers.20.conv1d.bias', 'model.layers.20.x_proj.weight', 'model.layers.20.dt_proj.weight', 'model.layers.20.dt_proj.bias', 'model.layers.20.out_proj.weight', 'model.layers.20.norm.weight', 'model.layers.21.A_log', 'model.layers.21.D', 'model.layers.21.in_proj.weight', 'model.layers.21.conv1d.weight', 'model.layers.21.conv1d.bias', 'model.layers.21.x_proj.weight', 'model.layers.21.dt_proj.weight', 'model.layers.21.dt_proj.bias', 'model.layers.21.out_proj.weight', 'model.layers.21.norm.weight', 'model.layers.22.A_log', 'model.layers.22.D', 'model.layers.22.in_proj.weight', 'model.layers.22.conv1d.weight', 'model.layers.22.conv1d.bias', 'model.layers.22.x_proj.weight', 'model.layers.22.dt_proj.weight', 'model.layers.22.dt_proj.bias', 'model.layers.22.out_proj.weight', 'model.layers.22.norm.weight', 'model.layers.23.A_log', 'model.layers.23.D', 'model.layers.23.in_proj.weight', 'model.layers.23.conv1d.weight', 'model.layers.23.conv1d.bias', 'model.layers.23.x_proj.weight', 'model.layers.23.dt_proj.weight', 'model.layers.23.dt_proj.bias', 'model.layers.23.out_proj.weight', 'model.layers.23.norm.weight', 'model.norm_f.weight', 'lm_head.weight'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df25a5cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MambaForCausalLM(\n",
       "  (model): MambaModel(\n",
       "    (embedding): Embedding(50280, 768)\n",
       "    (layers): ModuleList(\n",
       "      (0-23): 24 x MambaBlock(\n",
       "        (in_proj): Linear(in_features=768, out_features=3072, bias=False)\n",
       "        (conv1d): Conv1d(1536, 1536, kernel_size=(4,), stride=(1,), padding=(3,), groups=1536)\n",
       "        (x_proj): Linear(in_features=1536, out_features=80, bias=False)\n",
       "        (dt_proj): Linear(in_features=48, out_features=1536, bias=True)\n",
       "        (out_proj): Linear(in_features=1536, out_features=768, bias=False)\n",
       "        (norm): MambaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm_f): MambaRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50280, bias=False)\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed8cc33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['embedding.weight', 'layers.0.A_log', 'layers.0.D', 'layers.0.in_proj.weight', 'layers.0.conv1d.weight', 'layers.0.conv1d.bias', 'layers.0.x_proj.weight', 'layers.0.dt_proj.weight', 'layers.0.dt_proj.bias', 'layers.0.out_proj.weight', 'layers.0.norm.weight', 'layers.1.A_log', 'layers.1.D', 'layers.1.in_proj.weight', 'layers.1.conv1d.weight', 'layers.1.conv1d.bias', 'layers.1.x_proj.weight', 'layers.1.dt_proj.weight', 'layers.1.dt_proj.bias', 'layers.1.out_proj.weight', 'layers.1.norm.weight', 'layers.2.A_log', 'layers.2.D', 'layers.2.in_proj.weight', 'layers.2.conv1d.weight', 'layers.2.conv1d.bias', 'layers.2.x_proj.weight', 'layers.2.dt_proj.weight', 'layers.2.dt_proj.bias', 'layers.2.out_proj.weight', 'layers.2.norm.weight', 'layers.3.A_log', 'layers.3.D', 'layers.3.in_proj.weight', 'layers.3.conv1d.weight', 'layers.3.conv1d.bias', 'layers.3.x_proj.weight', 'layers.3.dt_proj.weight', 'layers.3.dt_proj.bias', 'layers.3.out_proj.weight', 'layers.3.norm.weight', 'layers.4.A_log', 'layers.4.D', 'layers.4.in_proj.weight', 'layers.4.conv1d.weight', 'layers.4.conv1d.bias', 'layers.4.x_proj.weight', 'layers.4.dt_proj.weight', 'layers.4.dt_proj.bias', 'layers.4.out_proj.weight', 'layers.4.norm.weight', 'layers.5.A_log', 'layers.5.D', 'layers.5.in_proj.weight', 'layers.5.conv1d.weight', 'layers.5.conv1d.bias', 'layers.5.x_proj.weight', 'layers.5.dt_proj.weight', 'layers.5.dt_proj.bias', 'layers.5.out_proj.weight', 'layers.5.norm.weight', 'layers.6.A_log', 'layers.6.D', 'layers.6.in_proj.weight', 'layers.6.conv1d.weight', 'layers.6.conv1d.bias', 'layers.6.x_proj.weight', 'layers.6.dt_proj.weight', 'layers.6.dt_proj.bias', 'layers.6.out_proj.weight', 'layers.6.norm.weight', 'layers.7.A_log', 'layers.7.D', 'layers.7.in_proj.weight', 'layers.7.conv1d.weight', 'layers.7.conv1d.bias', 'layers.7.x_proj.weight', 'layers.7.dt_proj.weight', 'layers.7.dt_proj.bias', 'layers.7.out_proj.weight', 'layers.7.norm.weight', 'layers.8.A_log', 'layers.8.D', 'layers.8.in_proj.weight', 'layers.8.conv1d.weight', 'layers.8.conv1d.bias', 'layers.8.x_proj.weight', 'layers.8.dt_proj.weight', 'layers.8.dt_proj.bias', 'layers.8.out_proj.weight', 'layers.8.norm.weight', 'layers.9.A_log', 'layers.9.D', 'layers.9.in_proj.weight', 'layers.9.conv1d.weight', 'layers.9.conv1d.bias', 'layers.9.x_proj.weight', 'layers.9.dt_proj.weight', 'layers.9.dt_proj.bias', 'layers.9.out_proj.weight', 'layers.9.norm.weight', 'layers.10.A_log', 'layers.10.D', 'layers.10.in_proj.weight', 'layers.10.conv1d.weight', 'layers.10.conv1d.bias', 'layers.10.x_proj.weight', 'layers.10.dt_proj.weight', 'layers.10.dt_proj.bias', 'layers.10.out_proj.weight', 'layers.10.norm.weight', 'layers.11.A_log', 'layers.11.D', 'layers.11.in_proj.weight', 'layers.11.conv1d.weight', 'layers.11.conv1d.bias', 'layers.11.x_proj.weight', 'layers.11.dt_proj.weight', 'layers.11.dt_proj.bias', 'layers.11.out_proj.weight', 'layers.11.norm.weight', 'layers.12.A_log', 'layers.12.D', 'layers.12.in_proj.weight', 'layers.12.conv1d.weight', 'layers.12.conv1d.bias', 'layers.12.x_proj.weight', 'layers.12.dt_proj.weight', 'layers.12.dt_proj.bias', 'layers.12.out_proj.weight', 'layers.12.norm.weight', 'layers.13.A_log', 'layers.13.D', 'layers.13.in_proj.weight', 'layers.13.conv1d.weight', 'layers.13.conv1d.bias', 'layers.13.x_proj.weight', 'layers.13.dt_proj.weight', 'layers.13.dt_proj.bias', 'layers.13.out_proj.weight', 'layers.13.norm.weight', 'layers.14.A_log', 'layers.14.D', 'layers.14.in_proj.weight', 'layers.14.conv1d.weight', 'layers.14.conv1d.bias', 'layers.14.x_proj.weight', 'layers.14.dt_proj.weight', 'layers.14.dt_proj.bias', 'layers.14.out_proj.weight', 'layers.14.norm.weight', 'layers.15.A_log', 'layers.15.D', 'layers.15.in_proj.weight', 'layers.15.conv1d.weight', 'layers.15.conv1d.bias', 'layers.15.x_proj.weight', 'layers.15.dt_proj.weight', 'layers.15.dt_proj.bias', 'layers.15.out_proj.weight', 'layers.15.norm.weight', 'layers.16.A_log', 'layers.16.D', 'layers.16.in_proj.weight', 'layers.16.conv1d.weight', 'layers.16.conv1d.bias', 'layers.16.x_proj.weight', 'layers.16.dt_proj.weight', 'layers.16.dt_proj.bias', 'layers.16.out_proj.weight', 'layers.16.norm.weight', 'layers.17.A_log', 'layers.17.D', 'layers.17.in_proj.weight', 'layers.17.conv1d.weight', 'layers.17.conv1d.bias', 'layers.17.x_proj.weight', 'layers.17.dt_proj.weight', 'layers.17.dt_proj.bias', 'layers.17.out_proj.weight', 'layers.17.norm.weight', 'layers.18.A_log', 'layers.18.D', 'layers.18.in_proj.weight', 'layers.18.conv1d.weight', 'layers.18.conv1d.bias', 'layers.18.x_proj.weight', 'layers.18.dt_proj.weight', 'layers.18.dt_proj.bias', 'layers.18.out_proj.weight', 'layers.18.norm.weight', 'layers.19.A_log', 'layers.19.D', 'layers.19.in_proj.weight', 'layers.19.conv1d.weight', 'layers.19.conv1d.bias', 'layers.19.x_proj.weight', 'layers.19.dt_proj.weight', 'layers.19.dt_proj.bias', 'layers.19.out_proj.weight', 'layers.19.norm.weight', 'layers.20.A_log', 'layers.20.D', 'layers.20.in_proj.weight', 'layers.20.conv1d.weight', 'layers.20.conv1d.bias', 'layers.20.x_proj.weight', 'layers.20.dt_proj.weight', 'layers.20.dt_proj.bias', 'layers.20.out_proj.weight', 'layers.20.norm.weight', 'layers.21.A_log', 'layers.21.D', 'layers.21.in_proj.weight', 'layers.21.conv1d.weight', 'layers.21.conv1d.bias', 'layers.21.x_proj.weight', 'layers.21.dt_proj.weight', 'layers.21.dt_proj.bias', 'layers.21.out_proj.weight', 'layers.21.norm.weight', 'layers.22.A_log', 'layers.22.D', 'layers.22.in_proj.weight', 'layers.22.conv1d.weight', 'layers.22.conv1d.bias', 'layers.22.x_proj.weight', 'layers.22.dt_proj.weight', 'layers.22.dt_proj.bias', 'layers.22.out_proj.weight', 'layers.22.norm.weight', 'layers.23.A_log', 'layers.23.D', 'layers.23.in_proj.weight', 'layers.23.conv1d.weight', 'layers.23.conv1d.bias', 'layers.23.x_proj.weight', 'layers.23.dt_proj.weight', 'layers.23.dt_proj.bias', 'layers.23.out_proj.weight', 'layers.23.norm.weight', 'norm_f.weight'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.base_model.state_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c12953",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shane",
   "language": "python",
   "name": "shane"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
