{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2073977",
   "metadata": {},
   "source": [
    "### Load Pretrained Model\n",
    "Load a pretrained Mamba Model that is compatible with Transformers Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8338f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/soma/opt/anaconda3/envs/shane/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MambaConfig {\n",
      "  \"bias\": false,\n",
      "  \"conv_bias\": true,\n",
      "  \"d_conv\": 4,\n",
      "  \"d_inner\": 12,\n",
      "  \"d_model\": 6,\n",
      "  \"d_state\": 4,\n",
      "  \"dt_rank\": 1,\n",
      "  \"expand\": 2,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"model_type\": \"mamba\",\n",
      "  \"n_layer\": 1,\n",
      "  \"pad_vocab_size_multiple\": 8,\n",
      "  \"transformers_version\": \"4.37.1\",\n",
      "  \"vocab_size\": 16\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from modeling_mamba import MambaForCausalLM\n",
    "from configuration_mamba import MambaConfig\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "config = MambaConfig(vocab_size=10,\n",
    "        d_state=4,\n",
    "        d_model=6,\n",
    "        d_conv=4,\n",
    "        expand=2,\n",
    "        conv_bias=True,\n",
    "        bias=False,\n",
    "        n_layer=1)\n",
    "model = MambaForCausalLM(config)\n",
    "print(model.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db293bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "&&(((!!%%++%!..!\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('Q-bert/Mamba-130M')\n",
    "text = \"Hi\"\n",
    "input_ids = tokenizer.encode(text, return_tensors=\"pt\")\n",
    "input_ids[[0]]=0\n",
    "output = model.generate(input_ids, max_length=20, num_beams=5, no_repeat_ngram_size=2)\n",
    "generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4e5d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  0,  7,  7,  9,  9,  1,  1,  9,  2,  2,  6,  6, 12, 12,  6,  2, 15,\n",
      "         15,  2]])\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47713d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('', <class 'modeling_mamba.MambaForCausalLM'>), ('model', <class 'modeling_mamba.MambaModel'>), ('model.embedding', <class 'torch.nn.modules.sparse.Embedding'>), ('model.layers', <class 'torch.nn.modules.container.ModuleList'>), ('model.layers.0', <class 'modeling_mamba.MambaBlock'>), ('model.layers.0.in_proj', <class 'torch.nn.modules.linear.Linear'>), ('model.layers.0.conv1d', <class 'torch.nn.modules.conv.Conv1d'>), ('model.layers.0.x_proj', <class 'torch.nn.modules.linear.Linear'>), ('model.layers.0.dt_proj', <class 'torch.nn.modules.linear.Linear'>), ('model.layers.0.out_proj', <class 'torch.nn.modules.linear.Linear'>), ('model.layers.0.norm', <class 'modeling_mamba.MambaRMSNorm'>), ('model.norm_f', <class 'modeling_mamba.MambaRMSNorm'>), ('lm_head', <class 'torch.nn.modules.linear.Linear'>)]\n"
     ]
    }
   ],
   "source": [
    "print([(n, type(m)) for n, m in model.named_modules()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d639baf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'modeling_mamba.MambaForCausalLM'>\n",
      "trainable params: 576 || all params: 576 || trainable%: 100.0\n",
      "plain None\n"
     ]
    }
   ],
   "source": [
    "print(type(model))\n",
    "\n",
    "def print_trainable_parameters(model):\n",
    "    \"\"\"\n",
    "    Prints the number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
    "    )\n",
    "    \n",
    "print('plain',print_trainable_parameters(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5575f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.embedding.weight\n",
      "model.layers.0.A_log\n",
      "model.layers.0.D\n",
      "model.layers.0.in_proj.weight\n",
      "model.layers.0.conv1d.weight\n",
      "model.layers.0.conv1d.bias\n",
      "model.layers.0.x_proj.weight\n",
      "model.layers.0.dt_proj.weight\n",
      "model.layers.0.dt_proj.bias\n",
      "model.layers.0.out_proj.weight\n",
      "model.layers.0.norm.weight\n",
      "model.norm_f.weight\n",
      "lm_head.weight\n"
     ]
    }
   ],
   "source": [
    "plist = model.state_dict().keys()\n",
    "for p in plist:\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ccd41b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before tensor([[-6.9360e-03, -2.6066e-02, -1.5970e-02,  4.0102e-02, -5.7095e-03,\n",
      "          1.0152e-02],\n",
      "        [ 3.8860e-03, -2.1722e-02,  3.3430e-02,  2.1430e-02,  7.7757e-03,\n",
      "         -6.2078e-03],\n",
      "        [ 1.3417e-02, -6.0377e-03,  3.0089e-02,  8.0725e-03,  1.3436e-02,\n",
      "         -5.6337e-04],\n",
      "        [-4.7518e-04,  1.8928e-02,  1.5352e-02, -2.8361e-02, -3.0808e-03,\n",
      "         -9.0114e-03],\n",
      "        [ 1.4535e-02,  1.7960e-02,  2.4319e-03, -1.2897e-02, -2.4247e-02,\n",
      "          3.8146e-03],\n",
      "        [-2.8388e-02,  2.2076e-02, -1.9500e-02, -5.2615e-02, -9.7469e-03,\n",
      "         -6.6771e-03],\n",
      "        [-1.0930e-02,  5.9960e-03,  4.2091e-03, -1.9360e-02, -1.3724e-02,\n",
      "         -1.9674e-02],\n",
      "        [ 4.8153e-03, -8.1420e-03, -6.5606e-03,  2.0654e-02,  4.5150e-03,\n",
      "          3.9812e-02],\n",
      "        [-1.0122e-02, -3.5603e-03,  1.5604e-03,  1.6430e-02,  9.4992e-03,\n",
      "          2.0851e-02],\n",
      "        [-5.0829e-02, -1.2619e-02, -1.9031e-02, -2.3794e-02, -3.6052e-02,\n",
      "          1.8947e-02],\n",
      "        [-7.3191e-03,  1.4073e-02,  1.5945e-02, -2.9410e-03, -3.0404e-03,\n",
      "         -9.2843e-03],\n",
      "        [ 4.5578e-04, -1.8732e-03, -1.1253e-02, -2.7229e-02, -2.4461e-02,\n",
      "          2.9660e-03],\n",
      "        [ 1.6548e-02, -1.1803e-02,  1.0941e-04,  2.5101e-02, -1.6574e-02,\n",
      "         -1.0081e-02],\n",
      "        [-9.9482e-03, -2.1946e-03, -7.4535e-03, -2.9115e-03, -3.3569e-02,\n",
      "          1.6346e-03],\n",
      "        [ 3.4341e-03, -6.9704e-03,  3.3969e-02,  1.3586e-02,  3.3667e-03,\n",
      "         -6.5794e-03],\n",
      "        [ 2.3385e-02,  4.0027e-02,  6.6727e-03,  2.1036e-02, -2.2579e-02,\n",
      "          8.2811e-03],\n",
      "        [-3.7390e-02, -7.6052e-03, -7.2219e-04, -1.3285e-02,  2.0452e-02,\n",
      "          2.1950e-02],\n",
      "        [-2.8238e-02, -1.9645e-02,  5.9920e-03,  3.4383e-02, -1.3337e-02,\n",
      "          6.0271e-03],\n",
      "        [ 2.5995e-02,  1.9778e-02, -1.3446e-02, -1.0220e-02, -1.6376e-02,\n",
      "          4.0624e-03],\n",
      "        [-8.7433e-05, -1.8363e-02, -5.9265e-03,  1.0028e-02, -2.4242e-03,\n",
      "          4.4784e-02],\n",
      "        [ 6.5890e-03,  1.9062e-02,  4.6445e-03,  1.5925e-02,  1.7374e-02,\n",
      "         -1.0322e-02],\n",
      "        [ 1.2933e-02,  1.4369e-02,  1.4926e-02,  4.0870e-02, -6.6690e-03,\n",
      "          3.1323e-02],\n",
      "        [ 3.6643e-02,  3.2397e-03,  2.4506e-02, -2.0163e-02, -1.1869e-02,\n",
      "         -4.3392e-03],\n",
      "        [ 2.7655e-02, -1.0010e-02, -1.1495e-02,  1.4795e-02,  2.6052e-02,\n",
      "          7.7658e-03]])\n",
      "model.embedding.weight\n",
      "model.layers.0.A_log\n",
      "model.layers.0.D\n",
      "model.layers.0.in_proj.weight\n",
      "model.layers.0.conv1d.weight\n",
      "model.layers.0.conv1d.bias\n",
      "model.layers.0.x_proj.weight\n",
      "model.layers.0.dt_proj.weight\n",
      "model.layers.0.dt_proj.bias\n",
      "model.layers.0.out_proj.weight\n",
      "model.layers.0.norm.weight\n",
      "model.norm_f.weight\n",
      "lm_head.weight\n",
      "after tensor([[0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# set one tensor to zero\n",
    "import torch\n",
    "def zero_init(model):\n",
    "    state_dict_before = model.state_dict()\n",
    "    state_dict_after = state_dict_before\n",
    "    for p in state_dict_before:\n",
    "        wt = state_dict_before[p]\n",
    "        state_dict_after[p] = torch.zeros_like(wt)\n",
    "    model.load_state_dict(state_dict_after)\n",
    "    return model\n",
    "\n",
    "    \n",
    "s = 'model.layers.0.in_proj.weight'\n",
    "print('before',model.state_dict()[s])\n",
    "model = zero_init(model) \n",
    "plist = model.state_dict().keys()\n",
    "for p in plist:\n",
    "    print(p)\n",
    "print('after',model.state_dict()[s])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba6b4fe",
   "metadata": {},
   "source": [
    "### Add LoRA adapters\n",
    "1. Identify a particular layer in the Mamba and add an LoRA layer there\n",
    "2. At this time, is only layer to verify if the code works\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf338c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, TaskType\n",
    "\n",
    "\n",
    "target_modules=[\"model.layers.0.x_proj\"]\n",
    "\n",
    "config = LoraConfig(\n",
    "target_modules = target_modules,\n",
    "task_type=\"CAUSAL_LM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33dc0241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'cadam32bit_grad_fp32'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/soma/opt/anaconda3/envs/shane/lib/python3.9/site-packages/bitsandbytes/cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 168 || all params: 744 || trainable%: 22.580645161290324\n"
     ]
    }
   ],
   "source": [
    "from peft import get_peft_model\n",
    "\n",
    "model = get_peft_model(model, config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9532d4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/soma/opt/anaconda3/envs/shane/lib/python3.9/site-packages/peft/utils/save_and_load.py:148: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model.save_pretrained(\"wts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bfeb5cd",
   "metadata": {},
   "source": [
    "### Merge the adpater into the Model\n",
    "merge the adapter back to the model, so the merged model will have exactly the same architecture\n",
    "except with the weights modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90bccee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import PeftConfig, PeftModel\n",
    "adapter_path = \"./wts/\"\n",
    "adapter_config = PeftConfig.from_pretrained(adapter_path)\n",
    "\n",
    "\n",
    "config = MambaConfig(vocab_size=10,\n",
    "        d_state=4,\n",
    "        d_model=6,\n",
    "        d_conv=4,\n",
    "        expand=2,\n",
    "        conv_bias=True,\n",
    "        bias=False,\n",
    "        n_layer=1)\n",
    "\n",
    "model = MambaForCausalLM(config)\n",
    "base_model = MambaForCausalLM(config)\n",
    "#base_model = zero_init(base_model) \n",
    "\n",
    "adapted_model = PeftModel.from_pretrained(base_model, adapter_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504dc17a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "m = adapted_model.merge_and_unload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd27623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before LoRA tensor([[ 1.4849e-02, -1.2009e-02, -3.2689e-02, -2.5011e-02, -2.9925e-02,\n",
      "         -6.8935e-03, -4.2453e-03,  3.2285e-03,  2.1370e-02,  3.2274e-02,\n",
      "          2.5561e-02, -2.6172e-02],\n",
      "        [ 2.5374e-02, -2.7696e-02,  7.7958e-03, -4.7651e-03,  1.6143e-02,\n",
      "         -4.9373e-03,  6.4753e-02, -1.0391e-02,  4.0120e-02, -6.6447e-03,\n",
      "         -3.2088e-02, -9.7386e-03],\n",
      "        [-4.5022e-03,  1.0816e-02,  1.9747e-02,  2.6482e-03,  6.8737e-03,\n",
      "         -1.4123e-02, -4.2332e-03, -2.2343e-02,  3.7523e-03, -6.2664e-03,\n",
      "          1.6541e-02, -1.3695e-02],\n",
      "        [-2.3554e-03,  4.3192e-02, -4.4122e-02,  9.9059e-03, -3.0129e-02,\n",
      "         -5.0738e-03,  1.1388e-02, -3.4150e-02,  2.1487e-03, -6.1900e-03,\n",
      "         -1.0104e-02, -1.1733e-03],\n",
      "        [-8.2968e-03, -9.4233e-03, -1.0369e-02, -2.0514e-02, -1.0381e-02,\n",
      "          6.2013e-03, -1.6298e-02,  4.8816e-03,  9.1194e-03, -1.4476e-02,\n",
      "         -1.1100e-02, -2.4957e-02],\n",
      "        [ 1.0809e-02, -2.5367e-02, -1.1991e-02, -2.2620e-03, -1.0676e-03,\n",
      "          1.5558e-02,  2.4433e-02, -2.7997e-02,  3.3391e-02, -8.7951e-03,\n",
      "         -1.7579e-02,  2.1400e-02],\n",
      "        [ 1.9255e-02, -4.9832e-03,  1.3009e-03,  6.0162e-03, -1.0243e-02,\n",
      "         -2.2533e-02,  3.0941e-02,  1.0508e-02,  5.9159e-04, -1.3927e-02,\n",
      "          8.5137e-03, -2.0471e-02],\n",
      "        [ 2.3345e-03,  2.9523e-02, -3.9842e-02, -2.5739e-03, -4.1982e-02,\n",
      "         -3.1242e-02, -1.8837e-02,  2.8458e-02,  3.0416e-02,  1.3576e-02,\n",
      "         -2.2855e-02,  1.1225e-02],\n",
      "        [ 3.4721e-04, -8.3013e-03, -1.9363e-03, -5.4528e-05,  4.0640e-03,\n",
      "         -5.4966e-03,  4.6592e-02, -3.6861e-02, -1.9329e-02, -1.4379e-02,\n",
      "          1.9372e-02,  2.3114e-02]])\n",
      "model.embedding.weight\n",
      "model.layers.0.A_log\n",
      "model.layers.0.D\n",
      "model.layers.0.in_proj.weight\n",
      "model.layers.0.conv1d.weight\n",
      "model.layers.0.conv1d.bias\n",
      "model.layers.0.x_proj.weight\n",
      "model.layers.0.dt_proj.weight\n",
      "model.layers.0.dt_proj.bias\n",
      "model.layers.0.out_proj.weight\n",
      "model.layers.0.norm.weight\n",
      "model.norm_f.weight\n",
      "lm_head.weight\n",
      "after LoRA tensor([[ 1.4849e-02, -1.2009e-02, -3.2689e-02, -2.5011e-02, -2.9925e-02,\n",
      "         -6.8935e-03, -4.2453e-03,  3.2285e-03,  2.1370e-02,  3.2274e-02,\n",
      "          2.5561e-02, -2.6172e-02],\n",
      "        [ 2.5374e-02, -2.7696e-02,  7.7958e-03, -4.7651e-03,  1.6143e-02,\n",
      "         -4.9373e-03,  6.4753e-02, -1.0391e-02,  4.0120e-02, -6.6447e-03,\n",
      "         -3.2088e-02, -9.7386e-03],\n",
      "        [-4.5022e-03,  1.0816e-02,  1.9747e-02,  2.6482e-03,  6.8737e-03,\n",
      "         -1.4123e-02, -4.2332e-03, -2.2343e-02,  3.7523e-03, -6.2664e-03,\n",
      "          1.6541e-02, -1.3695e-02],\n",
      "        [-2.3554e-03,  4.3192e-02, -4.4122e-02,  9.9059e-03, -3.0129e-02,\n",
      "         -5.0738e-03,  1.1388e-02, -3.4150e-02,  2.1487e-03, -6.1900e-03,\n",
      "         -1.0104e-02, -1.1733e-03],\n",
      "        [-8.2968e-03, -9.4233e-03, -1.0369e-02, -2.0514e-02, -1.0381e-02,\n",
      "          6.2013e-03, -1.6298e-02,  4.8816e-03,  9.1194e-03, -1.4476e-02,\n",
      "         -1.1100e-02, -2.4957e-02],\n",
      "        [ 1.0809e-02, -2.5367e-02, -1.1991e-02, -2.2620e-03, -1.0676e-03,\n",
      "          1.5558e-02,  2.4433e-02, -2.7997e-02,  3.3391e-02, -8.7951e-03,\n",
      "         -1.7579e-02,  2.1400e-02],\n",
      "        [ 1.9255e-02, -4.9832e-03,  1.3009e-03,  6.0162e-03, -1.0243e-02,\n",
      "         -2.2533e-02,  3.0941e-02,  1.0508e-02,  5.9159e-04, -1.3927e-02,\n",
      "          8.5137e-03, -2.0471e-02],\n",
      "        [ 2.3345e-03,  2.9523e-02, -3.9842e-02, -2.5739e-03, -4.1982e-02,\n",
      "         -3.1242e-02, -1.8837e-02,  2.8458e-02,  3.0416e-02,  1.3576e-02,\n",
      "         -2.2855e-02,  1.1225e-02],\n",
      "        [ 3.4721e-04, -8.3013e-03, -1.9363e-03, -5.4528e-05,  4.0640e-03,\n",
      "         -5.4966e-03,  4.6592e-02, -3.6861e-02, -1.9329e-02, -1.4379e-02,\n",
      "          1.9372e-02,  2.3114e-02]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "s = \"model.layers.0.x_proj.weight\"\n",
    "print('before LoRA',base_model.state_dict()[s])\n",
    "\n",
    "plist = m.state_dict().keys()\n",
    "for p in plist:\n",
    "    print(p)\n",
    "print('after LoRA',m.state_dict()[s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36ab5c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ")),,$$##((**\"\"&&'&\n"
     ]
    }
   ],
   "source": [
    "text = \"Hi\"\n",
    "\n",
    "input_ids = tokenizer.encode(text, return_tensors=\"pt\")\n",
    "input_ids[[0]] = 0\n",
    "\n",
    "output = m.generate(input_ids, max_length=20, num_beams=5, no_repeat_ngram_size=2)\n",
    "\n",
    "generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6bbbfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 0 || all params: 576 || trainable%: 0.0\n",
      "base mamba None\n",
      "trainable params: 576 || all params: 576 || trainable%: 100.0\n",
      "lora mamba None\n",
      "trainable params: 0 || all params: 576 || trainable%: 0.0\n",
      "merged mamba None\n"
     ]
    }
   ],
   "source": [
    "print('base mamba',print_trainable_parameters(base_model))\n",
    "print('lora mamba',print_trainable_parameters(model))\n",
    "print('merged mamba',print_trainable_parameters(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f175fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.save_pretrained(\"./mbins\", from_pt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9521388b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.save(m, \"./mbins/merged_mamba.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97425c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(base_model, \"./mbins/base_mamba.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6b2752",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['base_model.model.model.embedding.weight', 'base_model.model.model.layers.0.A_log', 'base_model.model.model.layers.0.D', 'base_model.model.model.layers.0.in_proj.weight', 'base_model.model.model.layers.0.conv1d.weight', 'base_model.model.model.layers.0.conv1d.bias', 'base_model.model.model.layers.0.x_proj.weight', 'base_model.model.model.layers.0.dt_proj.weight', 'base_model.model.model.layers.0.dt_proj.bias', 'base_model.model.model.layers.0.out_proj.weight', 'base_model.model.model.layers.0.norm.weight', 'base_model.model.model.norm_f.weight', 'base_model.model.lm_head.weight'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adapted_model.state_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de9859e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LoraConfig(peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path='', revision=None, task_type='CAUSAL_LM', inference_mode=True, r=8, target_modules={'model.layers.0.x_proj'}, lora_alpha=8, lora_dropout=0.0, fan_in_fan_out=False, bias='none', use_rslora=False, modules_to_save=None, init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={}, megatron_config=None, megatron_core='megatron.core', loftq_config={})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adapter_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f60f9ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('base_model.model.model.embedding.weight', Parameter containing:\n",
      "tensor([[-1.5483e-02,  3.0647e-02,  3.3757e-03,  6.0129e-03,  5.4505e-03,\n",
      "         -3.5295e-02],\n",
      "        [ 1.5370e-02, -2.8087e-02, -6.7823e-03, -5.6044e-03, -1.5007e-04,\n",
      "         -4.3077e-03],\n",
      "        [ 1.4575e-02,  3.4753e-03,  1.3032e-02,  5.0821e-03, -1.3286e-02,\n",
      "          7.1539e-03],\n",
      "        [ 6.0257e-02, -9.3745e-03, -2.1507e-02,  1.9956e-02,  1.6579e-02,\n",
      "          3.0674e-03],\n",
      "        [-3.3371e-02, -9.4733e-03,  2.1177e-02, -1.1452e-02, -1.9490e-02,\n",
      "          2.5770e-02],\n",
      "        [-9.2815e-03,  3.1123e-02,  1.9363e-02, -5.0284e-03, -3.2319e-02,\n",
      "         -2.0659e-03],\n",
      "        [ 3.6841e-03, -1.2734e-02, -3.5888e-02,  8.8476e-03,  1.2994e-02,\n",
      "         -1.3616e-02],\n",
      "        [ 2.8832e-02, -5.4185e-03, -4.8067e-03,  4.3071e-03,  1.8272e-02,\n",
      "         -4.6660e-02],\n",
      "        [ 1.9783e-02, -2.1448e-02,  5.3043e-03, -1.1504e-02, -5.2285e-04,\n",
      "         -2.7710e-02],\n",
      "        [-3.3491e-04, -4.6580e-03,  2.9298e-02, -7.3879e-03,  1.1404e-02,\n",
      "          2.0229e-02],\n",
      "        [-2.1470e-02,  4.1981e-02, -2.5151e-02, -4.1565e-02,  9.4426e-03,\n",
      "         -5.9438e-03],\n",
      "        [ 3.2548e-02, -1.5286e-02,  2.7064e-02,  6.7357e-03,  3.8647e-02,\n",
      "         -5.0914e-03],\n",
      "        [-4.9104e-04,  3.5907e-03, -5.5168e-05, -9.6191e-03, -1.3269e-03,\n",
      "          4.2128e-03],\n",
      "        [-1.3604e-02,  3.6714e-02, -2.5137e-02,  2.9132e-03, -1.1330e-02,\n",
      "          2.8516e-02],\n",
      "        [ 2.4355e-02, -1.6240e-02,  6.2665e-04, -9.6788e-03, -6.7079e-03,\n",
      "         -1.4852e-02],\n",
      "        [ 7.5282e-03, -2.7487e-02,  2.8488e-02,  8.6867e-03, -3.2349e-02,\n",
      "         -3.0684e-03]]))\n",
      "('base_model.model.model.layers.0.A_log', Parameter containing:\n",
      "tensor([[0.0000, 0.6931, 1.0986, 1.3863],\n",
      "        [0.0000, 0.6931, 1.0986, 1.3863],\n",
      "        [0.0000, 0.6931, 1.0986, 1.3863],\n",
      "        [0.0000, 0.6931, 1.0986, 1.3863],\n",
      "        [0.0000, 0.6931, 1.0986, 1.3863],\n",
      "        [0.0000, 0.6931, 1.0986, 1.3863],\n",
      "        [0.0000, 0.6931, 1.0986, 1.3863],\n",
      "        [0.0000, 0.6931, 1.0986, 1.3863],\n",
      "        [0.0000, 0.6931, 1.0986, 1.3863],\n",
      "        [0.0000, 0.6931, 1.0986, 1.3863],\n",
      "        [0.0000, 0.6931, 1.0986, 1.3863],\n",
      "        [0.0000, 0.6931, 1.0986, 1.3863]]))\n",
      "('base_model.model.model.layers.0.D', Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]))\n",
      "('base_model.model.model.layers.0.in_proj.weight', Parameter containing:\n",
      "tensor([[-0.0241,  0.0047,  0.0114, -0.0088, -0.0149,  0.0095],\n",
      "        [ 0.0048,  0.0108, -0.0025, -0.0097,  0.0053, -0.0020],\n",
      "        [-0.0035, -0.0068, -0.0101,  0.0072, -0.0103,  0.0008],\n",
      "        [ 0.0016,  0.0247,  0.0041, -0.0014, -0.0074,  0.0006],\n",
      "        [ 0.0033, -0.0111, -0.0198, -0.0128, -0.0152,  0.0086],\n",
      "        [ 0.0082,  0.0136, -0.0273,  0.0244, -0.0184, -0.0201],\n",
      "        [ 0.0062, -0.0058,  0.0141,  0.0141, -0.0176, -0.0228],\n",
      "        [-0.0027,  0.0069, -0.0462,  0.0018, -0.0111,  0.0315],\n",
      "        [ 0.0197,  0.0127, -0.0003, -0.0046, -0.0131,  0.0444],\n",
      "        [ 0.0019, -0.0010, -0.0176, -0.0109, -0.0242,  0.0110],\n",
      "        [-0.0175,  0.0151, -0.0487,  0.0012,  0.0159, -0.0029],\n",
      "        [-0.0303, -0.0280, -0.0081,  0.0061,  0.0181, -0.0262],\n",
      "        [-0.0297, -0.0205,  0.0305,  0.0140, -0.0369, -0.0159],\n",
      "        [-0.0201, -0.0047, -0.0180,  0.0168,  0.0080,  0.0129],\n",
      "        [ 0.0226, -0.0399, -0.0232,  0.0208, -0.0233,  0.0071],\n",
      "        [ 0.0237,  0.0324,  0.0088,  0.0410,  0.0040,  0.0263],\n",
      "        [-0.0081, -0.0073, -0.0037,  0.0088,  0.0139,  0.0024],\n",
      "        [-0.0251, -0.0160, -0.0158,  0.0080,  0.0266, -0.0089],\n",
      "        [-0.0063,  0.0056, -0.0105, -0.0178,  0.0250,  0.0500],\n",
      "        [-0.0177,  0.0036, -0.0199,  0.0375,  0.0276,  0.0028],\n",
      "        [-0.0476,  0.0118, -0.0086,  0.0080, -0.0092,  0.0100],\n",
      "        [-0.0033,  0.0075,  0.0060,  0.0206,  0.0023,  0.0111],\n",
      "        [-0.0077,  0.0184, -0.0088,  0.0052, -0.0020,  0.0084],\n",
      "        [-0.0152, -0.0178, -0.0269, -0.0102, -0.0160,  0.0305]]))\n",
      "('base_model.model.model.layers.0.conv1d.weight', Parameter containing:\n",
      "tensor([[[ 0.0267,  0.0249, -0.0181, -0.0339]],\n",
      "\n",
      "        [[-0.0189, -0.0074, -0.0194, -0.0017]],\n",
      "\n",
      "        [[ 0.0296, -0.0027,  0.0112, -0.0116]],\n",
      "\n",
      "        [[ 0.0075,  0.0159, -0.0078, -0.0030]],\n",
      "\n",
      "        [[ 0.0223, -0.0112, -0.0052, -0.0216]],\n",
      "\n",
      "        [[ 0.0123, -0.0121,  0.0123, -0.0167]],\n",
      "\n",
      "        [[-0.0296, -0.0088,  0.0609, -0.0117]],\n",
      "\n",
      "        [[ 0.0052,  0.0029, -0.0059,  0.0183]],\n",
      "\n",
      "        [[-0.0143, -0.0078, -0.0073, -0.0223]],\n",
      "\n",
      "        [[ 0.0212,  0.0193,  0.0084, -0.0089]],\n",
      "\n",
      "        [[-0.0031,  0.0029,  0.0149,  0.0094]],\n",
      "\n",
      "        [[-0.0204, -0.0148, -0.0136, -0.0341]]]))\n",
      "('base_model.model.model.layers.0.conv1d.bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]))\n",
      "('base_model.model.model.layers.0.x_proj.weight', Parameter containing:\n",
      "tensor([[ 1.4849e-02, -1.2009e-02, -3.2689e-02, -2.5011e-02, -2.9925e-02,\n",
      "         -6.8935e-03, -4.2453e-03,  3.2285e-03,  2.1370e-02,  3.2274e-02,\n",
      "          2.5561e-02, -2.6172e-02],\n",
      "        [ 2.5374e-02, -2.7696e-02,  7.7958e-03, -4.7651e-03,  1.6143e-02,\n",
      "         -4.9373e-03,  6.4753e-02, -1.0391e-02,  4.0120e-02, -6.6447e-03,\n",
      "         -3.2088e-02, -9.7386e-03],\n",
      "        [-4.5022e-03,  1.0816e-02,  1.9747e-02,  2.6482e-03,  6.8737e-03,\n",
      "         -1.4123e-02, -4.2332e-03, -2.2343e-02,  3.7523e-03, -6.2664e-03,\n",
      "          1.6541e-02, -1.3695e-02],\n",
      "        [-2.3554e-03,  4.3192e-02, -4.4122e-02,  9.9059e-03, -3.0129e-02,\n",
      "         -5.0738e-03,  1.1388e-02, -3.4150e-02,  2.1487e-03, -6.1900e-03,\n",
      "         -1.0104e-02, -1.1733e-03],\n",
      "        [-8.2968e-03, -9.4233e-03, -1.0369e-02, -2.0514e-02, -1.0381e-02,\n",
      "          6.2013e-03, -1.6298e-02,  4.8816e-03,  9.1194e-03, -1.4476e-02,\n",
      "         -1.1100e-02, -2.4957e-02],\n",
      "        [ 1.0809e-02, -2.5367e-02, -1.1991e-02, -2.2620e-03, -1.0676e-03,\n",
      "          1.5558e-02,  2.4433e-02, -2.7997e-02,  3.3391e-02, -8.7951e-03,\n",
      "         -1.7579e-02,  2.1400e-02],\n",
      "        [ 1.9255e-02, -4.9832e-03,  1.3009e-03,  6.0162e-03, -1.0243e-02,\n",
      "         -2.2533e-02,  3.0941e-02,  1.0508e-02,  5.9159e-04, -1.3927e-02,\n",
      "          8.5137e-03, -2.0471e-02],\n",
      "        [ 2.3345e-03,  2.9523e-02, -3.9842e-02, -2.5739e-03, -4.1982e-02,\n",
      "         -3.1242e-02, -1.8837e-02,  2.8458e-02,  3.0416e-02,  1.3576e-02,\n",
      "         -2.2855e-02,  1.1225e-02],\n",
      "        [ 3.4721e-04, -8.3013e-03, -1.9363e-03, -5.4528e-05,  4.0640e-03,\n",
      "         -5.4966e-03,  4.6592e-02, -3.6861e-02, -1.9329e-02, -1.4379e-02,\n",
      "          1.9372e-02,  2.3114e-02]]))\n",
      "('base_model.model.model.layers.0.dt_proj.weight', Parameter containing:\n",
      "tensor([[-0.0245],\n",
      "        [ 0.0104],\n",
      "        [-0.0316],\n",
      "        [-0.0494],\n",
      "        [ 0.0249],\n",
      "        [-0.0320],\n",
      "        [-0.0369],\n",
      "        [ 0.0088],\n",
      "        [-0.0003],\n",
      "        [-0.0246],\n",
      "        [ 0.0109],\n",
      "        [ 0.0170]]))\n",
      "('base_model.model.model.layers.0.dt_proj.bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]))\n",
      "('base_model.model.model.layers.0.out_proj.weight', Parameter containing:\n",
      "tensor([[-0.0188, -0.0175,  0.0196,  0.0057,  0.0098,  0.0173,  0.0239, -0.0060,\n",
      "         -0.0150, -0.0399,  0.0478, -0.0378],\n",
      "        [ 0.0170,  0.0099, -0.0004, -0.0384,  0.0227,  0.0082,  0.0188, -0.0065,\n",
      "         -0.0120,  0.0172, -0.0028, -0.0037],\n",
      "        [-0.0316, -0.0004,  0.0387, -0.0091,  0.0134,  0.0115, -0.0120, -0.0078,\n",
      "         -0.0156,  0.0238,  0.0064,  0.0103],\n",
      "        [-0.0046, -0.0255,  0.0210,  0.0019,  0.0223,  0.0297,  0.0031, -0.0015,\n",
      "         -0.0181,  0.0064,  0.0115,  0.0200],\n",
      "        [-0.0331, -0.0043, -0.0268, -0.0050,  0.0205,  0.0139, -0.0161, -0.0178,\n",
      "          0.0052,  0.0143,  0.0194, -0.0097],\n",
      "        [-0.0035, -0.0078,  0.0112, -0.0078,  0.0108, -0.0195, -0.0008, -0.0207,\n",
      "         -0.0318, -0.0152,  0.0024,  0.0337]]))\n",
      "('base_model.model.model.layers.0.norm.weight', Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1.]))\n",
      "('base_model.model.model.norm_f.weight', Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1.]))\n"
     ]
    }
   ],
   "source": [
    "for p in adapted_model.named_parameters():\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d1e06a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shane",
   "language": "python",
   "name": "shane"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
