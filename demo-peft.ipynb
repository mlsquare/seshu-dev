{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "531467a2-5160-4073-a990-0d81d574b014",
   "metadata": {},
   "source": [
    "## (1) Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9337043-4e7a-4b20-9d89-6c6257245334",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/soma/opt/anaconda3/envs/shane/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/soma/opt/anaconda3/envs/shane/lib/python3.9/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from model import Mamba, ModelArgs\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# One of:\n",
    "#     'state-spaces/mamba-2.8b-slimpj'\n",
    "#     'state-spaces/mamba-2.8b'\n",
    "#     'state-spaces/mamba-1.4b'\n",
    "#     'state-spaces/mamba-790m'\n",
    "#     'state-spaces/mamba-370m'\n",
    "#     'state-spaces/mamba-130m'\n",
    "pretrained_model_name = 'state-spaces/mamba-370m'\n",
    "\n",
    "model = Mamba.from_pretrained(pretrained_model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained('EleutherAI/gpt-neox-20b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c01c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 371516416 || all params: 371516416 || trainable%: 100.0\n",
      "plain None\n"
     ]
    }
   ],
   "source": [
    "def print_trainable_parameters(model):\n",
    "    \"\"\"\n",
    "    Prints the number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
    "    )\n",
    "    \n",
    "print('plain',print_trainable_parameters(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2efb17-37ad-472b-b029-9567acf17629",
   "metadata": {},
   "source": [
    "## (2) Generate Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b2d62d-0d95-4a3f-bd98-aa37e3f26b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def generate(model,\n",
    "             tokenizer,\n",
    "             prompt: str,\n",
    "             n_tokens_to_gen: int = 50,\n",
    "             sample: bool = True,\n",
    "             top_k: int = 40):\n",
    "    model.eval()\n",
    "    \n",
    "    input_ids = tokenizer(prompt, return_tensors='pt').input_ids\n",
    "    \n",
    "    for token_n in range(n_tokens_to_gen):\n",
    "        with torch.no_grad():\n",
    "            indices_to_input = input_ids\n",
    "            next_token_logits = model(indices_to_input)[:, -1]\n",
    "        \n",
    "        probs = F.softmax(next_token_logits, dim=-1)\n",
    "        (batch, vocab_size) = probs.shape\n",
    "        \n",
    "        if top_k is not None:\n",
    "            (values, indices) = torch.topk(probs, k=top_k)\n",
    "            probs[probs < values[:, -1, None]] = 0\n",
    "            probs = probs / probs.sum(axis=1, keepdims=True)\n",
    "        \n",
    "        if sample:\n",
    "            next_indices = torch.multinomial(probs, num_samples=1)\n",
    "        else:\n",
    "            next_indices = torch.argmax(probs, dim=-1)[:, None]\n",
    "        \n",
    "        input_ids = torch.cat([input_ids, next_indices], dim=1)\n",
    "\n",
    "    output_completions = [tokenizer.decode(output.tolist()) for output in input_ids][0]\n",
    "    \n",
    "    return output_completions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1e3d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('', <class 'model.Mamba'>), ('embedding', <class 'torch.nn.modules.sparse.Embedding'>), ('layers', <class 'torch.nn.modules.container.ModuleList'>), ('layers.0', <class 'model.ResidualBlock'>), ('layers.0.mixer', <class 'model.MambaBlock'>), ('layers.0.mixer.in_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.0.mixer.conv1d', <class 'torch.nn.modules.conv.Conv1d'>), ('layers.0.mixer.x_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.0.mixer.dt_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.0.mixer.out_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.0.norm', <class 'model.RMSNorm'>), ('layers.1', <class 'model.ResidualBlock'>), ('layers.1.mixer', <class 'model.MambaBlock'>), ('layers.1.mixer.in_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.1.mixer.conv1d', <class 'torch.nn.modules.conv.Conv1d'>), ('layers.1.mixer.x_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.1.mixer.dt_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.1.mixer.out_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.1.norm', <class 'model.RMSNorm'>), ('layers.2', <class 'model.ResidualBlock'>), ('layers.2.mixer', <class 'model.MambaBlock'>), ('layers.2.mixer.in_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.2.mixer.conv1d', <class 'torch.nn.modules.conv.Conv1d'>), ('layers.2.mixer.x_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.2.mixer.dt_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.2.mixer.out_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.2.norm', <class 'model.RMSNorm'>), ('layers.3', <class 'model.ResidualBlock'>), ('layers.3.mixer', <class 'model.MambaBlock'>), ('layers.3.mixer.in_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.3.mixer.conv1d', <class 'torch.nn.modules.conv.Conv1d'>), ('layers.3.mixer.x_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.3.mixer.dt_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.3.mixer.out_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.3.norm', <class 'model.RMSNorm'>), ('layers.4', <class 'model.ResidualBlock'>), ('layers.4.mixer', <class 'model.MambaBlock'>), ('layers.4.mixer.in_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.4.mixer.conv1d', <class 'torch.nn.modules.conv.Conv1d'>), ('layers.4.mixer.x_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.4.mixer.dt_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.4.mixer.out_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.4.norm', <class 'model.RMSNorm'>), ('layers.5', <class 'model.ResidualBlock'>), ('layers.5.mixer', <class 'model.MambaBlock'>), ('layers.5.mixer.in_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.5.mixer.conv1d', <class 'torch.nn.modules.conv.Conv1d'>), ('layers.5.mixer.x_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.5.mixer.dt_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.5.mixer.out_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.5.norm', <class 'model.RMSNorm'>), ('layers.6', <class 'model.ResidualBlock'>), ('layers.6.mixer', <class 'model.MambaBlock'>), ('layers.6.mixer.in_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.6.mixer.conv1d', <class 'torch.nn.modules.conv.Conv1d'>), ('layers.6.mixer.x_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.6.mixer.dt_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.6.mixer.out_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.6.norm', <class 'model.RMSNorm'>), ('layers.7', <class 'model.ResidualBlock'>), ('layers.7.mixer', <class 'model.MambaBlock'>), ('layers.7.mixer.in_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.7.mixer.conv1d', <class 'torch.nn.modules.conv.Conv1d'>), ('layers.7.mixer.x_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.7.mixer.dt_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.7.mixer.out_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.7.norm', <class 'model.RMSNorm'>), ('layers.8', <class 'model.ResidualBlock'>), ('layers.8.mixer', <class 'model.MambaBlock'>), ('layers.8.mixer.in_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.8.mixer.conv1d', <class 'torch.nn.modules.conv.Conv1d'>), ('layers.8.mixer.x_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.8.mixer.dt_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.8.mixer.out_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.8.norm', <class 'model.RMSNorm'>), ('layers.9', <class 'model.ResidualBlock'>), ('layers.9.mixer', <class 'model.MambaBlock'>), ('layers.9.mixer.in_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.9.mixer.conv1d', <class 'torch.nn.modules.conv.Conv1d'>), ('layers.9.mixer.x_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.9.mixer.dt_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.9.mixer.out_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.9.norm', <class 'model.RMSNorm'>), ('layers.10', <class 'model.ResidualBlock'>), ('layers.10.mixer', <class 'model.MambaBlock'>), ('layers.10.mixer.in_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.10.mixer.conv1d', <class 'torch.nn.modules.conv.Conv1d'>), ('layers.10.mixer.x_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.10.mixer.dt_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.10.mixer.out_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.10.norm', <class 'model.RMSNorm'>), ('layers.11', <class 'model.ResidualBlock'>), ('layers.11.mixer', <class 'model.MambaBlock'>), ('layers.11.mixer.in_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.11.mixer.conv1d', <class 'torch.nn.modules.conv.Conv1d'>), ('layers.11.mixer.x_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.11.mixer.dt_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.11.mixer.out_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.11.norm', <class 'model.RMSNorm'>), ('layers.12', <class 'model.ResidualBlock'>), ('layers.12.mixer', <class 'model.MambaBlock'>), ('layers.12.mixer.in_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.12.mixer.conv1d', <class 'torch.nn.modules.conv.Conv1d'>), ('layers.12.mixer.x_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.12.mixer.dt_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.12.mixer.out_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.12.norm', <class 'model.RMSNorm'>), ('layers.13', <class 'model.ResidualBlock'>), ('layers.13.mixer', <class 'model.MambaBlock'>), ('layers.13.mixer.in_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.13.mixer.conv1d', <class 'torch.nn.modules.conv.Conv1d'>), ('layers.13.mixer.x_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.13.mixer.dt_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.13.mixer.out_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.13.norm', <class 'model.RMSNorm'>), ('layers.14', <class 'model.ResidualBlock'>), ('layers.14.mixer', <class 'model.MambaBlock'>), ('layers.14.mixer.in_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.14.mixer.conv1d', <class 'torch.nn.modules.conv.Conv1d'>), ('layers.14.mixer.x_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.14.mixer.dt_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.14.mixer.out_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.14.norm', <class 'model.RMSNorm'>), ('layers.15', <class 'model.ResidualBlock'>), ('layers.15.mixer', <class 'model.MambaBlock'>), ('layers.15.mixer.in_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.15.mixer.conv1d', <class 'torch.nn.modules.conv.Conv1d'>), ('layers.15.mixer.x_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.15.mixer.dt_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.15.mixer.out_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.15.norm', <class 'model.RMSNorm'>), ('layers.16', <class 'model.ResidualBlock'>), ('layers.16.mixer', <class 'model.MambaBlock'>), ('layers.16.mixer.in_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.16.mixer.conv1d', <class 'torch.nn.modules.conv.Conv1d'>), ('layers.16.mixer.x_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.16.mixer.dt_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.16.mixer.out_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.16.norm', <class 'model.RMSNorm'>), ('layers.17', <class 'model.ResidualBlock'>), ('layers.17.mixer', <class 'model.MambaBlock'>), ('layers.17.mixer.in_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.17.mixer.conv1d', <class 'torch.nn.modules.conv.Conv1d'>), ('layers.17.mixer.x_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.17.mixer.dt_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.17.mixer.out_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.17.norm', <class 'model.RMSNorm'>), ('layers.18', <class 'model.ResidualBlock'>), ('layers.18.mixer', <class 'model.MambaBlock'>), ('layers.18.mixer.in_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.18.mixer.conv1d', <class 'torch.nn.modules.conv.Conv1d'>), ('layers.18.mixer.x_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.18.mixer.dt_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.18.mixer.out_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.18.norm', <class 'model.RMSNorm'>), ('layers.19', <class 'model.ResidualBlock'>), ('layers.19.mixer', <class 'model.MambaBlock'>), ('layers.19.mixer.in_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.19.mixer.conv1d', <class 'torch.nn.modules.conv.Conv1d'>), ('layers.19.mixer.x_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.19.mixer.dt_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.19.mixer.out_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.19.norm', <class 'model.RMSNorm'>), ('layers.20', <class 'model.ResidualBlock'>), ('layers.20.mixer', <class 'model.MambaBlock'>), ('layers.20.mixer.in_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.20.mixer.conv1d', <class 'torch.nn.modules.conv.Conv1d'>), ('layers.20.mixer.x_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.20.mixer.dt_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.20.mixer.out_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.20.norm', <class 'model.RMSNorm'>), ('layers.21', <class 'model.ResidualBlock'>), ('layers.21.mixer', <class 'model.MambaBlock'>), ('layers.21.mixer.in_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.21.mixer.conv1d', <class 'torch.nn.modules.conv.Conv1d'>), ('layers.21.mixer.x_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.21.mixer.dt_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.21.mixer.out_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.21.norm', <class 'model.RMSNorm'>), ('layers.22', <class 'model.ResidualBlock'>), ('layers.22.mixer', <class 'model.MambaBlock'>), ('layers.22.mixer.in_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.22.mixer.conv1d', <class 'torch.nn.modules.conv.Conv1d'>), ('layers.22.mixer.x_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.22.mixer.dt_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.22.mixer.out_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.22.norm', <class 'model.RMSNorm'>), ('layers.23', <class 'model.ResidualBlock'>), ('layers.23.mixer', <class 'model.MambaBlock'>), ('layers.23.mixer.in_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.23.mixer.conv1d', <class 'torch.nn.modules.conv.Conv1d'>), ('layers.23.mixer.x_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.23.mixer.dt_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.23.mixer.out_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.23.norm', <class 'model.RMSNorm'>), ('layers.24', <class 'model.ResidualBlock'>), ('layers.24.mixer', <class 'model.MambaBlock'>), ('layers.24.mixer.in_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.24.mixer.conv1d', <class 'torch.nn.modules.conv.Conv1d'>), ('layers.24.mixer.x_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.24.mixer.dt_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.24.mixer.out_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.24.norm', <class 'model.RMSNorm'>), ('layers.25', <class 'model.ResidualBlock'>), ('layers.25.mixer', <class 'model.MambaBlock'>), ('layers.25.mixer.in_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.25.mixer.conv1d', <class 'torch.nn.modules.conv.Conv1d'>), ('layers.25.mixer.x_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.25.mixer.dt_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.25.mixer.out_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.25.norm', <class 'model.RMSNorm'>), ('layers.26', <class 'model.ResidualBlock'>), ('layers.26.mixer', <class 'model.MambaBlock'>), ('layers.26.mixer.in_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.26.mixer.conv1d', <class 'torch.nn.modules.conv.Conv1d'>), ('layers.26.mixer.x_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.26.mixer.dt_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.26.mixer.out_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.26.norm', <class 'model.RMSNorm'>), ('layers.27', <class 'model.ResidualBlock'>), ('layers.27.mixer', <class 'model.MambaBlock'>), ('layers.27.mixer.in_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.27.mixer.conv1d', <class 'torch.nn.modules.conv.Conv1d'>), ('layers.27.mixer.x_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.27.mixer.dt_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.27.mixer.out_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.27.norm', <class 'model.RMSNorm'>), ('layers.28', <class 'model.ResidualBlock'>), ('layers.28.mixer', <class 'model.MambaBlock'>), ('layers.28.mixer.in_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.28.mixer.conv1d', <class 'torch.nn.modules.conv.Conv1d'>), ('layers.28.mixer.x_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.28.mixer.dt_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.28.mixer.out_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.28.norm', <class 'model.RMSNorm'>), ('layers.29', <class 'model.ResidualBlock'>), ('layers.29.mixer', <class 'model.MambaBlock'>), ('layers.29.mixer.in_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.29.mixer.conv1d', <class 'torch.nn.modules.conv.Conv1d'>), ('layers.29.mixer.x_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.29.mixer.dt_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.29.mixer.out_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.29.norm', <class 'model.RMSNorm'>), ('layers.30', <class 'model.ResidualBlock'>), ('layers.30.mixer', <class 'model.MambaBlock'>), ('layers.30.mixer.in_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.30.mixer.conv1d', <class 'torch.nn.modules.conv.Conv1d'>), ('layers.30.mixer.x_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.30.mixer.dt_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.30.mixer.out_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.30.norm', <class 'model.RMSNorm'>), ('layers.31', <class 'model.ResidualBlock'>), ('layers.31.mixer', <class 'model.MambaBlock'>), ('layers.31.mixer.in_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.31.mixer.conv1d', <class 'torch.nn.modules.conv.Conv1d'>), ('layers.31.mixer.x_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.31.mixer.dt_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.31.mixer.out_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.31.norm', <class 'model.RMSNorm'>), ('layers.32', <class 'model.ResidualBlock'>), ('layers.32.mixer', <class 'model.MambaBlock'>), ('layers.32.mixer.in_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.32.mixer.conv1d', <class 'torch.nn.modules.conv.Conv1d'>), ('layers.32.mixer.x_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.32.mixer.dt_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.32.mixer.out_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.32.norm', <class 'model.RMSNorm'>), ('layers.33', <class 'model.ResidualBlock'>), ('layers.33.mixer', <class 'model.MambaBlock'>), ('layers.33.mixer.in_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.33.mixer.conv1d', <class 'torch.nn.modules.conv.Conv1d'>), ('layers.33.mixer.x_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.33.mixer.dt_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.33.mixer.out_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.33.norm', <class 'model.RMSNorm'>), ('layers.34', <class 'model.ResidualBlock'>), ('layers.34.mixer', <class 'model.MambaBlock'>), ('layers.34.mixer.in_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.34.mixer.conv1d', <class 'torch.nn.modules.conv.Conv1d'>), ('layers.34.mixer.x_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.34.mixer.dt_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.34.mixer.out_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.34.norm', <class 'model.RMSNorm'>), ('layers.35', <class 'model.ResidualBlock'>), ('layers.35.mixer', <class 'model.MambaBlock'>), ('layers.35.mixer.in_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.35.mixer.conv1d', <class 'torch.nn.modules.conv.Conv1d'>), ('layers.35.mixer.x_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.35.mixer.dt_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.35.mixer.out_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.35.norm', <class 'model.RMSNorm'>), ('layers.36', <class 'model.ResidualBlock'>), ('layers.36.mixer', <class 'model.MambaBlock'>), ('layers.36.mixer.in_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.36.mixer.conv1d', <class 'torch.nn.modules.conv.Conv1d'>), ('layers.36.mixer.x_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.36.mixer.dt_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.36.mixer.out_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.36.norm', <class 'model.RMSNorm'>), ('layers.37', <class 'model.ResidualBlock'>), ('layers.37.mixer', <class 'model.MambaBlock'>), ('layers.37.mixer.in_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.37.mixer.conv1d', <class 'torch.nn.modules.conv.Conv1d'>), ('layers.37.mixer.x_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.37.mixer.dt_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.37.mixer.out_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.37.norm', <class 'model.RMSNorm'>), ('layers.38', <class 'model.ResidualBlock'>), ('layers.38.mixer', <class 'model.MambaBlock'>), ('layers.38.mixer.in_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.38.mixer.conv1d', <class 'torch.nn.modules.conv.Conv1d'>), ('layers.38.mixer.x_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.38.mixer.dt_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.38.mixer.out_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.38.norm', <class 'model.RMSNorm'>), ('layers.39', <class 'model.ResidualBlock'>), ('layers.39.mixer', <class 'model.MambaBlock'>), ('layers.39.mixer.in_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.39.mixer.conv1d', <class 'torch.nn.modules.conv.Conv1d'>), ('layers.39.mixer.x_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.39.mixer.dt_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.39.mixer.out_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.39.norm', <class 'model.RMSNorm'>), ('layers.40', <class 'model.ResidualBlock'>), ('layers.40.mixer', <class 'model.MambaBlock'>), ('layers.40.mixer.in_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.40.mixer.conv1d', <class 'torch.nn.modules.conv.Conv1d'>), ('layers.40.mixer.x_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.40.mixer.dt_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.40.mixer.out_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.40.norm', <class 'model.RMSNorm'>), ('layers.41', <class 'model.ResidualBlock'>), ('layers.41.mixer', <class 'model.MambaBlock'>), ('layers.41.mixer.in_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.41.mixer.conv1d', <class 'torch.nn.modules.conv.Conv1d'>), ('layers.41.mixer.x_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.41.mixer.dt_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.41.mixer.out_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.41.norm', <class 'model.RMSNorm'>), ('layers.42', <class 'model.ResidualBlock'>), ('layers.42.mixer', <class 'model.MambaBlock'>), ('layers.42.mixer.in_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.42.mixer.conv1d', <class 'torch.nn.modules.conv.Conv1d'>), ('layers.42.mixer.x_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.42.mixer.dt_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.42.mixer.out_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.42.norm', <class 'model.RMSNorm'>), ('layers.43', <class 'model.ResidualBlock'>), ('layers.43.mixer', <class 'model.MambaBlock'>), ('layers.43.mixer.in_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.43.mixer.conv1d', <class 'torch.nn.modules.conv.Conv1d'>), ('layers.43.mixer.x_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.43.mixer.dt_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.43.mixer.out_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.43.norm', <class 'model.RMSNorm'>), ('layers.44', <class 'model.ResidualBlock'>), ('layers.44.mixer', <class 'model.MambaBlock'>), ('layers.44.mixer.in_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.44.mixer.conv1d', <class 'torch.nn.modules.conv.Conv1d'>), ('layers.44.mixer.x_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.44.mixer.dt_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.44.mixer.out_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.44.norm', <class 'model.RMSNorm'>), ('layers.45', <class 'model.ResidualBlock'>), ('layers.45.mixer', <class 'model.MambaBlock'>), ('layers.45.mixer.in_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.45.mixer.conv1d', <class 'torch.nn.modules.conv.Conv1d'>), ('layers.45.mixer.x_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.45.mixer.dt_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.45.mixer.out_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.45.norm', <class 'model.RMSNorm'>), ('layers.46', <class 'model.ResidualBlock'>), ('layers.46.mixer', <class 'model.MambaBlock'>), ('layers.46.mixer.in_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.46.mixer.conv1d', <class 'torch.nn.modules.conv.Conv1d'>), ('layers.46.mixer.x_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.46.mixer.dt_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.46.mixer.out_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.46.norm', <class 'model.RMSNorm'>), ('layers.47', <class 'model.ResidualBlock'>), ('layers.47.mixer', <class 'model.MambaBlock'>), ('layers.47.mixer.in_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.47.mixer.conv1d', <class 'torch.nn.modules.conv.Conv1d'>), ('layers.47.mixer.x_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.47.mixer.dt_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.47.mixer.out_proj', <class 'torch.nn.modules.linear.Linear'>), ('layers.47.norm', <class 'model.RMSNorm'>), ('norm_f', <class 'model.RMSNorm'>), ('lm_head', <class 'torch.nn.modules.linear.Linear'>)]\n"
     ]
    }
   ],
   "source": [
    "print([(n, type(m)) for n, m in model.named_modules()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f821c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, TaskType\n",
    "\n",
    "\n",
    "target_modules=[\"layers.3.mixer.x_proj\"]\n",
    "\n",
    "config = LoraConfig(\n",
    "target_modules = target_modules,\n",
    "task_type=\"CAUSAL_LM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd2d668",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/soma/opt/anaconda3/envs/shane/lib/python3.9/site-packages/bitsandbytes/cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'cadam32bit_grad_fp32'\n"
     ]
    }
   ],
   "source": [
    "from peft import inject_adapter_in_model\n",
    "\n",
    "lora_model = inject_adapter_in_model(config, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a46b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 17152 || all params: 371533568 || trainable%: 0.004616541135793146\n",
      "plain None\n"
     ]
    }
   ],
   "source": [
    "print('plain',print_trainable_parameters(lora_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d689ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-31 03:34:29.185079: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mamba is the only non-Chinese state with a state police force, with the equivalent of a national police force in the UK.\n",
      "\n",
      "Mamba has also made some very significant political progress in this regard:\n",
      "\n",
      "Mamba has enacted laws mandating the creation\n"
     ]
    }
   ],
   "source": [
    "print(generate(lora_model, tokenizer, 'Mamba is the'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b49c764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'model.Mamba'>\n"
     ]
    }
   ],
   "source": [
    "print(type(lora_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b81568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'layers.3.mixer.x_proj.lora_A.weight': tensor([[-0.0032,  0.0019,  0.0140,  ..., -0.0199,  0.0010,  0.0003],\n",
      "        [ 0.0139, -0.0139, -0.0160,  ..., -0.0196,  0.0200,  0.0203],\n",
      "        [ 0.0144, -0.0075,  0.0207,  ..., -0.0170, -0.0111, -0.0078],\n",
      "        ...,\n",
      "        [ 0.0062,  0.0019,  0.0108,  ...,  0.0043, -0.0008, -0.0218],\n",
      "        [-0.0195,  0.0128, -0.0065,  ..., -0.0089,  0.0001,  0.0003],\n",
      "        [ 0.0138,  0.0171, -0.0142,  ...,  0.0109,  0.0140, -0.0115]]), 'layers.3.mixer.x_proj.lora_B.weight': tensor([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.]])}\n"
     ]
    }
   ],
   "source": [
    "from peft import get_peft_model_state_dict\n",
    "\n",
    "peft_state_dict = get_peft_model_state_dict(lora_model)\n",
    "print(peft_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8985e797",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_model.save_pretrained(lora_adapter, save_adapter=True, save_config=True)\n",
    "\n",
    "model_to_merge = PeftModel.from_pretrained(AutoModelForCausalLM.from_pretrained(base_model).to(“cuda”), lora_adapter)\n",
    "\n",
    "merged_model = model_to_merge.merge_and_unload()\n",
    "merged_model.save_pretrained(merged_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shane",
   "language": "python",
   "name": "shane"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
